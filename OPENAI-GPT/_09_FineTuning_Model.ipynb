{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning a Model - ChatBot Example\n",
    "\n",
    "In this project, we'll explore how to fine-tune a GPT model such as text-babbage model with our own data set. You should note, this may not be needed for more advanced text-davinci models or future GPT-4 models, but let's explore the process of creating our \n",
    "own custom fine-tuning data set, formatting it for OpenAI, and then training and calling our own custom model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8226b80dd5d52778"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Library Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7a7e68414cade9"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:07.645428Z",
     "start_time": "2023-10-13T06:52:06.743288Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Q&A Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d121c2cd3a5e2254"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n0  11060        912.0  2008-08-14T13:59:21Z                   NaN     18   \n1  17250        394.0  2008-08-20T00:16:40Z                   NaN     24   \n2  31340     242853.0  2008-08-27T23:44:47Z                   NaN     71   \n3  34020       3561.0  2008-08-29T05:43:16Z                   NaN     17   \n4  34570        577.0  2008-08-29T16:10:41Z  2011-11-08T16:11:43Z     13   \n\n                                               Title  \\\n0           How should I unit test a code-generator?   \n1             Create an encrypted ZIP file in Python   \n2  How do threads work in Python, and what are co...   \n3                          Are Python threads buggy?   \n4  What is the best quick-read Python book out th...   \n\n                                                Body  ParentId  \\\n0  This is a difficult and open-ended question I ...     11060   \n1  I'm creating an ZIP file with ZipFile in Pytho...     17250   \n2  I've been trying to wrap my head around how th...     31340   \n3  A reliable coder friend told me that Python's ...     34020   \n4  I am taking a class that requires Python. We w...     34570   \n\n                                              Answer  \n0  I started writing up a summary of my experienc...  \n1  I created a simple library to create a passwor...  \n2  Yes, because of the Global Interpreter Lock (G...  \n3  Python threads are good for concurrent I/O pro...  \n4  I loved Dive Into Python, especially if you're...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>OwnerUserId</th>\n      <th>CreationDate</th>\n      <th>ClosedDate</th>\n      <th>Score</th>\n      <th>Title</th>\n      <th>Body</th>\n      <th>ParentId</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11060</td>\n      <td>912.0</td>\n      <td>2008-08-14T13:59:21Z</td>\n      <td>NaN</td>\n      <td>18</td>\n      <td>How should I unit test a code-generator?</td>\n      <td>This is a difficult and open-ended question I ...</td>\n      <td>11060</td>\n      <td>I started writing up a summary of my experienc...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17250</td>\n      <td>394.0</td>\n      <td>2008-08-20T00:16:40Z</td>\n      <td>NaN</td>\n      <td>24</td>\n      <td>Create an encrypted ZIP file in Python</td>\n      <td>I'm creating an ZIP file with ZipFile in Pytho...</td>\n      <td>17250</td>\n      <td>I created a simple library to create a passwor...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>31340</td>\n      <td>242853.0</td>\n      <td>2008-08-27T23:44:47Z</td>\n      <td>NaN</td>\n      <td>71</td>\n      <td>How do threads work in Python, and what are co...</td>\n      <td>I've been trying to wrap my head around how th...</td>\n      <td>31340</td>\n      <td>Yes, because of the Global Interpreter Lock (G...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34020</td>\n      <td>3561.0</td>\n      <td>2008-08-29T05:43:16Z</td>\n      <td>NaN</td>\n      <td>17</td>\n      <td>Are Python threads buggy?</td>\n      <td>A reliable coder friend told me that Python's ...</td>\n      <td>34020</td>\n      <td>Python threads are good for concurrent I/O pro...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34570</td>\n      <td>577.0</td>\n      <td>2008-08-29T16:10:41Z</td>\n      <td>2011-11-08T16:11:43Z</td>\n      <td>13</td>\n      <td>What is the best quick-read Python book out th...</td>\n      <td>I am taking a class that requires Python. We w...</td>\n      <td>34570</td>\n      <td>I loved Dive Into Python, especially if you're...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv(\"/Volumes/Data/Datasets/genai_datasets/python_qa.csv\")\n",
    "data_frame.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:09.688729Z",
     "start_time": "2023-10-13T06:52:09.466677Z"
    }
   },
   "id": "b151fe293ced5a56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Formatting for Fine Tuning\n",
    "\n",
    "The formatting for a fine-tuning data set involves a prompt and expected completion. This leads fine-tuning to be a great choice for dialogue instances, such as question and answer or customer support.\n",
    "\n",
    "The format should look like the following (a list of dictionaries): <br><br>\n",
    "\n",
    "    [{\"prompt\": \"some prompt string\",\"completion\":\"the best completed text option given the prompt\"},]\n",
    "    \n",
    "\n",
    "Convert the information from CSV to the fine tuning format"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f39f4e766578e86"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "questions, answers = data_frame[\"Body\"], data_frame[\"Answer\"] # Use tuple Unpacking"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:11.540176Z",
     "start_time": "2023-10-13T06:52:11.533309Z"
    }
   },
   "id": "9aa23c5646778716"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0    This is a difficult and open-ended question I ...\n1    I'm creating an ZIP file with ZipFile in Pytho...\n2    I've been trying to wrap my head around how th...\n3    A reliable coder friend told me that Python's ...\n4    I am taking a class that requires Python. We w...\nName: Body, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:12.320354Z",
     "start_time": "2023-10-13T06:52:12.307689Z"
    }
   },
   "id": "2b6294e43d07a857"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0    I started writing up a summary of my experienc...\n1    I created a simple library to create a passwor...\n2    Yes, because of the Global Interpreter Lock (G...\n3    Python threads are good for concurrent I/O pro...\n4    I loved Dive Into Python, especially if you're...\nName: Answer, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:13.074355Z",
     "start_time": "2023-10-13T06:52:13.065774Z"
    }
   },
   "id": "1dd7b202df1fdd4a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'prompt': \"I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\\n\\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.\\n\",\n 'completion': \"pylint is the best such tool I've found. Due to Python's nature it's difficult to statically analyze it, but it will catch undefined variables, basic type errors, unused code, etc. You'll want to tweak the configuration file, as by default it outputs many warnings I consider useless or harmful.\\n\\nHere's part of my .pylintrc dealing with warning silencing:\\n\\n[MESSAGES CONTROL]\\n\\n# Brain-dead errors regarding standard language features\\n#   W0142 = *args and **kwargs support\\n#   W0403 = Relative imports\\n\\n# Pointless whinging\\n#   R0201 = Method could be a function\\n#   W0212 = Accessing protected attribute of client class\\n#   W0613 = Unused argument\\n#   W0232 = Class has no __init__ method\\n#   R0903 = Too few public methods\\n#   C0301 = Line too long\\n#   R0913 = Too many arguments\\n#   C0103 = Invalid name\\n#   R0914 = Too many local variables\\n\\n# PyLint's module importation is unreliable\\n#   F0401 = Unable to import module\\n#   W0402 = Uses of a deprecated module\\n\\n# Already an error when wildcard imports are used\\n#   W0614 = Unused import from wildcard\\n\\n# Sometimes disabled depending on how bad a module is\\n#   C0111 = Missing docstring\\n\\n# Disable the message(s) with the given id(s).\\ndisable=W0142,W0403,R0201,W0212,W0613,W0232,R0903,W0614,C0111,C0301,R0913,C0103,F0401,W0402,R0914\\n\\n\"}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will create the list of dictionary in the format\n",
    "qa_openai_format = [{\"prompt\": q, \"completion\": a} for q, a in zip(questions, answers)]\n",
    "qa_openai_format[5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:13.976840Z",
     "start_time": "2023-10-13T06:52:13.971050Z"
    }
   },
   "id": "96f4882c4ed4f235"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "4429"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of the training prompt\n",
    "len(qa_openai_format)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:14.741589Z",
     "start_time": "2023-10-13T06:52:14.734437Z"
    }
   },
   "id": "8de0f8671a219c17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Price Estimation\n",
    "\n",
    "In case you are ever worried about how many tokens your text actually has (to get an estimate of your costs) OpenAI has a library called \"tiktoken\", which allows you to estimate a cost based on token counts.\n",
    "\n",
    "Splitting text strings into tokens is useful because models like GPT-3 see text in the form of tokens. Knowing how many tokens are in a text string can tell you (a) whether the string is too long for a text model to process and (b) how much an OpenAI API call costs (as usage is priced by token). Different models use different encodings.\n",
    "\n",
    "**tiktoken** supports 3 different encodings for OpenAI models:\n",
    "\n",
    "* \"gpt2\" for most gpt-3 models\n",
    "* \"p50k_base\" for code models, and Davinci models, like \"text-davinci-003\"\n",
    "* \"cl100k_base\" for text-embedding-ada-002\n",
    "\n",
    "Make sure to view the pricing page on the OpenAI page for full information, for now, we'll cut down the data size so we don't spend too much money during training."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae5af145c1470f10"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string, encoding_name):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:17.167366Z",
     "start_time": "2023-10-13T06:52:17.160873Z"
    }
   },
   "id": "b1b67fc8066364f3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# In order to minimize cost, we would just consider the first 500 entries from our openai format and dump it in a json file\n",
    "dataset_size = 500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:18.274558Z",
     "start_time": "2023-10-13T06:52:18.266294Z"
    }
   },
   "id": "aff752e138b02875"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# From our format, extract the same number of records\n",
    "with open(\"training_data.json\", 'w') as f:\n",
    "    for entry in qa_openai_format[:dataset_size]:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:21.297554Z",
     "start_time": "2023-10-13T06:52:21.282976Z"
    }
   },
   "id": "b184e18a7c1a46e3"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Now lets find out the number of tokens\n",
    "token_counter = 0\n",
    "for element in qa_openai_format[:dataset_size]:\n",
    "    for key, value in element.items():\n",
    "        token_counter += num_tokens_from_string(value, 'p50k_base')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:22.298967Z",
     "start_time": "2023-10-13T06:52:22.026274Z"
    }
   },
   "id": "74be810412ea8529"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 184352 tokens\n",
      "Fine tuning using babbage costs $0.0004 per 1000 tokens\n",
      "Estimated price: $0.29496320000000004\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {token_counter} tokens\")\n",
    "print(f\"Fine tuning using babbage costs $0.0004 per 1000 tokens\")\n",
    "print(f\"Estimated price: ${(4*token_counter / 1000) * 0.0004}\") # 4 is the number of epochs we want it to train "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:23.045057Z",
     "start_time": "2023-10-13T06:52:23.037886Z"
    }
   },
   "id": "d26c070ce377ea16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Command Line for Fine-Tuning\n",
    "\n",
    "Note, you can find the full official guide here:\n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning\n",
    "\n",
    "OpenAI recommends using the terminal/command line via their OpenAI tool, which you have by simply running:\n",
    "\n",
    "    pip install --upgrade openai\n",
    "\n",
    "\n",
    "Now you can head over to the terminal to fine tune the model using the following command:\n",
    "\n",
    "    openai api fine_tunes.create -t training_data.json -m babbage"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd11059d54f191c4"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T06:52:54.899534Z",
     "start_time": "2023-10-13T06:52:54.892940Z"
    }
   },
   "id": "813bde6b9896816d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create a file for fine-tuning in OpenAI from training data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f01564efa19a31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### First we will check the training data - run the below command in the terminal\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f training_data.json\n",
    "\n",
    "This may change the file and make corrections as well"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e6b67efdfce0f0"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<File file id=file-HADD8dWUGwBJdPGMrKyjFyKj at 0x11dbeaed0> JSON: {\n  \"object\": \"file\",\n  \"id\": \"file-HADD8dWUGwBJdPGMrKyjFyKj\",\n  \"purpose\": \"fine-tune\",\n  \"filename\": \"file\",\n  \"bytes\": 705795,\n  \"created_at\": 1697180782,\n  \"status\": \"uploaded\",\n  \"status_details\": null\n}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the training data\n",
    "upload_response = openai.File.create(file=open(\"training_data_prepared.jsonl\", \"rb\"),\n",
    "                                     purpose='fine-tune'\n",
    "                                     )\n",
    "\n",
    "file_id = upload_response.id\n",
    "upload_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:06:22.889424Z",
     "start_time": "2023-10-13T07:06:20.102043Z"
    }
   },
   "id": "1a55e0489a56e46c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The File Id is - file-HADD8dWUGwBJdPGMrKyjFyKj\n"
     ]
    }
   ],
   "source": [
    "print(f\"The File Id is - {file_id}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:06:30.816023Z",
     "start_time": "2023-10-13T07:06:30.806395Z"
    }
   },
   "id": "bb54abed87f90bc2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the fine tuned model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4242dc3d619d7f5"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'babbage-002'.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Start the fine-tuning job\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m fine_tune_response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFineTuningJob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfile_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbabbage-002\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m fine_tune_response\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_resources/abstract/createable_api_resource.py:57\u001B[0m, in \u001B[0;36mCreateableAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     47\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m     48\u001B[0m ):\n\u001B[1;32m     49\u001B[0m     requestor, url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__prepare_create_requestor(\n\u001B[1;32m     50\u001B[0m         api_key,\n\u001B[1;32m     51\u001B[0m         api_base,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     54\u001B[0m         organization,\n\u001B[1;32m     55\u001B[0m     )\n\u001B[0;32m---> 57\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m util\u001B[38;5;241m.\u001B[39mconvert_to_openai_object(\n\u001B[1;32m     62\u001B[0m         response,\n\u001B[1;32m     63\u001B[0m         api_key,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     66\u001B[0m         plain_old_data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mplain_old_data,\n\u001B[1;32m     67\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:299\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    280\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    287\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    288\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    289\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    290\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    291\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    297\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    298\u001B[0m     )\n\u001B[0;32m--> 299\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:710\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    703\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[1;32m    704\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    705\u001B[0m         )\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[1;32m    707\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 710\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    712\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    716\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    717\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:775\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    773\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    774\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 775\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[1;32m    776\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[1;32m    777\u001B[0m     )\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mRateLimitError\u001B[0m: This fine-tune request has been rate-limited. Your organization has reached the maximum of 3 active requests (0 running, 3 pending) for the model 'babbage-002'."
     ]
    }
   ],
   "source": [
    "# Start the fine-tuning job\n",
    "fine_tune_response = openai.FineTuningJob.create(training_file=file_id, model=\"babbage-002\")\n",
    "fine_tune_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T07:19:33.230893Z",
     "start_time": "2023-10-13T07:19:32.777817Z"
    }
   },
   "id": "b61f15481f123ea8"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<FineTuningJob fine_tuning.job id=ftjob-qNcnOctH6reo59nuBay70tRW at 0x1219fa210> JSON: {\n  \"object\": \"fine_tuning.job\",\n  \"id\": \"ftjob-qNcnOctH6reo59nuBay70tRW\",\n  \"model\": \"davinci-002\",\n  \"created_at\": 1697181372,\n  \"finished_at\": null,\n  \"fine_tuned_model\": null,\n  \"organization_id\": \"org-sVuYSPcznA6bMq4ub2FKJWEb\",\n  \"result_files\": [],\n  \"status\": \"validating_files\",\n  \"validation_file\": null,\n  \"training_file\": \"file-HADD8dWUGwBJdPGMrKyjFyKj\",\n  \"hyperparameters\": {\n    \"n_epochs\": \"auto\"\n  },\n  \"trained_tokens\": null,\n  \"error\": null\n}"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:08:44.099194Z",
     "start_time": "2023-10-13T09:08:44.090546Z"
    }
   },
   "id": "8d6979c039c4c2ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check fine tuning progress\n",
    "\n",
    "#### Option 1 - List Events"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2256d505e5b8a636"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "## fine_tune_events = openai.FineTune.list_events(id=fine_tune_response.id)\n",
    "## fine_tune_events"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:19:58.372102Z",
     "start_time": "2023-10-13T09:19:58.363621Z"
    }
   },
   "id": "6c0f0596be2971c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Option 2 - List Response"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1172e207e73ca806"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "No fine-tune job: ftjob-qNcnOctH6reo59nuBay70tRW",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m retreive_response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFineTune\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mid\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mftjob-qNcnOctH6reo59nuBay70tRW\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m retreive_response\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_resources/abstract/api_resource.py:20\u001B[0m, in \u001B[0;36mAPIResource.retrieve\u001B[0;34m(cls, id, api_key, request_id, request_timeout, **params)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mretrieve\u001B[39m(\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mcls\u001B[39m, \u001B[38;5;28mid\u001B[39m, api_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, request_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, request_timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m     18\u001B[0m ):\n\u001B[1;32m     19\u001B[0m     instance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\u001B[38;5;28mid\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mid\u001B[39m, api_key\u001B[38;5;241m=\u001B[39mapi_key, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m---> 20\u001B[0m     \u001B[43minstance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrefresh\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m instance\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_resources/abstract/api_resource.py:32\u001B[0m, in \u001B[0;36mAPIResource.refresh\u001B[0;34m(self, request_id, request_timeout)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrefresh\u001B[39m(\u001B[38;5;28mself\u001B[39m, request_id\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, request_timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefresh_from(\n\u001B[0;32m---> 32\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     33\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minstance_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m     )\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/openai_object.py:179\u001B[0m, in \u001B[0;36mOpenAIObject.request\u001B[0;34m(self, method, url, params, headers, stream, plain_old_data, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    171\u001B[0m     params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve_params\n\u001B[1;32m    172\u001B[0m requestor \u001B[38;5;241m=\u001B[39m api_requestor\u001B[38;5;241m.\u001B[39mAPIRequestor(\n\u001B[1;32m    173\u001B[0m     key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key,\n\u001B[1;32m    174\u001B[0m     api_base\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_base_override \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_base(),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    177\u001B[0m     organization\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morganization,\n\u001B[1;32m    178\u001B[0m )\n\u001B[0;32m--> 179\u001B[0m response, stream, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)  \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:299\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    280\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    287\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    288\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    289\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    290\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    291\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    297\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    298\u001B[0m     )\n\u001B[0;32m--> 299\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:710\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    703\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[1;32m    704\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    705\u001B[0m         )\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[1;32m    707\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 710\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    712\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    716\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    717\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:775\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    773\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    774\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 775\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[1;32m    776\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[1;32m    777\u001B[0m     )\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mInvalidRequestError\u001B[0m: No fine-tune job: ftjob-qNcnOctH6reo59nuBay70tRW"
     ]
    }
   ],
   "source": [
    "## retreive_response = openai.FineTune.retrieve(id=\"ftjob-qNcnOctH6reo59nuBay70tRW\")\n",
    "## retreive_response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:10:00.063385Z",
     "start_time": "2023-10-13T09:09:59.618730Z"
    }
   },
   "id": "16da6a466f80052a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### By mistake we created lot of training jobs :) . we will test each of the fit model individually on the prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cede1c5f5afa8516"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
    "\n",
    "\n",
    "https://norahsakal.com/blog/fine-tune-gpt3-model <br></br>\n",
    "\n",
    "#### Check the status of the fit-jobs in \n",
    "https://platform.openai.com/finetune\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac8d561c48d46807"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Once the fine tuning is complete, we can save the model\n",
    "\n",
    "\n",
    "##### Option 1 | if response.fine_tuned_model != null\n",
    "fine_tuned_model = fine_tune_response.fine_tuned_model\n",
    "fine_tuned_model\n",
    "\n",
    "###### Option 2 | if response.fine_tuned_model == null\n",
    "retrieve_response = openai.FineTune.retrieve(fine_tune_response.id)\n",
    "fine_tuned_model = retrieve_response.fine_tuned_model\n",
    "fine_tuned_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c67312de59039950"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "new_prompt = \"What are some good python books?\\n\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:28:32.583061Z",
     "start_time": "2023-10-13T09:28:32.575098Z"
    }
   },
   "id": "c41b705f3e9f8566"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Cookbook - Brian Goetz\n",
      "\n",
      "Learning Python - Mark Lutz\n",
      "\n",
      "Programming Python - Martin v. Löwis\n",
      "\n",
      "Python in a Nutshell - Steven D. Bellovin\n",
      "\n",
      "\n",
      "Python Recipes - Mark Lutz\n",
      "\n",
      "\n",
      "The Tao of Python - Steven D. Bellovin\n",
      "\n",
      "\n",
      "Learn Python the Hard Way - Mark Lutz\n",
      "\n",
      "The Art of Python Programming - Brian W. Kernighan\n",
      "\n",
      "\n",
      "The Python Programming Language - L. L. Guare\n",
      "\n",
      "\n",
      "Learning Python - 2nd Edition - Michael J. Miller\n",
      "\n",
      "\n",
      "The Python Programming Language - L. L. Guare\n",
      "\n",
      "\n",
      "Learning Python - 3rd Edition - John E. Mason\n"
     ]
    }
   ],
   "source": [
    " response = openai.Completion.create(\n",
    "    model=\"ft:babbage-002:suvo-personal::897zBUYZ\",\n",
    "    prompt=new_prompt,\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0\n",
    ")\n",
    "\n",
    "# Check the response\n",
    "print(response['choices'][0]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:29:43.421824Z",
     "start_time": "2023-10-13T09:29:41.493215Z"
    }
   },
   "id": "fc6d6fbb8aa921fc"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some good ones that I have read:\n",
      "\n",
      "- The Python Programming Language\n",
      "- Advanced Python Programming\n",
      "- The Definitive Guide to Python (this is mine, by the way)\n",
      "- The Python Programming Language, 3rd Edition\n",
      "- The Little Python Book\n",
      "- The Tao of Python\n",
      "- The Python Programming Language\n",
      "- Python Pocket Reference\n",
      "- The Little Book of Python Concurrency\n",
      "- The Art of Python Programming\n",
      "- The Python Programming Language\n",
      "- The Art of Python Design (A Book Apart Book #5)\n",
      "- The Python 2.5 Reference Manual\n",
      "- The Python Programming Language, 2nd Edition\n"
     ]
    }
   ],
   "source": [
    " response = openai.Completion.create(\n",
    "    model=\"ft:babbage-002:suvo-personal::897zk2FY\",\n",
    "    prompt=new_prompt,\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0\n",
    ")\n",
    "\n",
    "# Check the response\n",
    "print(response['choices'][0]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:31:11.594145Z",
     "start_time": "2023-10-13T09:31:09.053502Z"
    }
   },
   "id": "d0db22494e4a274e"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm an amateur python programmer and I'm looking for good books to learn python programming from. I'm still a beginner so anything from advanced beginner to intermediate would be fine. I've read a few books that are a bit more advanced but I haven't found any that are the best and most complete books. Python Design Patterns is one of the best I've read. It's been out for a while, but still very much the best. It's a bit old, but I think it's still the most complete.\n",
      " Also, I've been using Python Cookbook which I'm finding to be very complete, although not as polished as the\n"
     ]
    }
   ],
   "source": [
    " response = openai.Completion.create(\n",
    "    model=\"ft:babbage-002:suvo-personal::8980Aj6M\",\n",
    "    prompt=new_prompt,\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0\n",
    ")\n",
    "\n",
    "# Check the response\n",
    "print(response['choices'][0]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:32:13.764040Z",
     "start_time": "2023-10-13T09:32:10.063053Z"
    }
   },
   "id": "e58bdc1c1907da47"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I've read *Automate the Boring Stuff with Python* and *Python Crash Course* and I'm looking for some more books which are at a beginner/intermediate level. \n",
      " I've also enjoyed  Flavio Copes' Learn You Some Erlang For Great Good!  which is a similar approach to Hitchhiker's Guide to learn a functional programming language.\n",
      "\n",
      "Some other books that will be helpful as you dig deeper into Python:\n",
      "\n",
      "Dive Into Python 3 by Mark Pilgrim\n",
      "\n",
      "This is the best free book available for learning Python 3.  It is not a beginner book.  Advanced topics are covered\n"
     ]
    }
   ],
   "source": [
    "# This is with davinci\n",
    "response = openai.Completion.create(\n",
    "    model=\"ft:davinci-002:suvo-personal::898HZgHU\",\n",
    "    prompt=new_prompt,\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0\n",
    ")\n",
    "\n",
    "# Check the response\n",
    "print(response['choices'][0]['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T09:33:16.478441Z",
     "start_time": "2023-10-13T09:33:10.533976Z"
    }
   },
   "id": "fa9367e3ee8fd115"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lets delete all the fine tuned models and files"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b148ab408020687"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The model 'ft:davinci-002:suvo-personal::898HZgHU' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Delete the fined tuned models\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mft:davinci-002:suvo-personal::898HZgHU\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_resources/abstract/deletable_api_resource.py:38\u001B[0m, in \u001B[0;36mDeletableAPIResource.delete\u001B[0;34m(cls, sid, api_type, api_version, **params)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdelete\u001B[39m(\u001B[38;5;28mcls\u001B[39m, sid, api_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, api_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams):\n\u001B[1;32m     36\u001B[0m     url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__prepare_delete(sid, api_type, api_version)\n\u001B[0;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_static_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdelete\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mapi_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_version\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_resources/abstract/api_resource.py:130\u001B[0m, in \u001B[0;36mAPIResource._static_request\u001B[0;34m(cls, method_, url_, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_static_request\u001B[39m(\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    122\u001B[0m ):\n\u001B[1;32m    123\u001B[0m     requestor \u001B[38;5;241m=\u001B[39m api_requestor\u001B[38;5;241m.\u001B[39mAPIRequestor(\n\u001B[1;32m    124\u001B[0m         api_key,\n\u001B[1;32m    125\u001B[0m         api_version\u001B[38;5;241m=\u001B[39mapi_version,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    128\u001B[0m         api_type\u001B[38;5;241m=\u001B[39mapi_type,\n\u001B[1;32m    129\u001B[0m     )\n\u001B[0;32m--> 130\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\n\u001B[1;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m util\u001B[38;5;241m.\u001B[39mconvert_to_openai_object(\n\u001B[1;32m    134\u001B[0m         response, api_key, api_version, organization\n\u001B[1;32m    135\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:299\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    279\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    280\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    287\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    288\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    289\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    290\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    291\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    297\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    298\u001B[0m     )\n\u001B[0;32m--> 299\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:710\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    702\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    703\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[1;32m    704\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    705\u001B[0m         )\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[1;32m    707\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    708\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 710\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    712\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    714\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    715\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    716\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    717\u001B[0m     )\n",
      "File \u001B[0;32m/usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages/openai/api_requestor.py:775\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    773\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    774\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 775\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[1;32m    776\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[1;32m    777\u001B[0m     )\n\u001B[1;32m    778\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mInvalidRequestError\u001B[0m: The model 'ft:davinci-002:suvo-personal::898HZgHU' does not exist"
     ]
    }
   ],
   "source": [
    "# Delete the fined tuned models\n",
    "openai.Model.delete(\"ft:davinci-002:suvo-personal::898HZgHU\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T10:09:29.921038Z",
     "start_time": "2023-10-13T10:09:29.466873Z"
    }
   },
   "id": "7f98d6624882f05a"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<File file id=file-OtfnvW0y7zHP28ly9h5rQzkn at 0x121d40b30> JSON: {\n  \"object\": \"file\",\n  \"id\": \"file-OtfnvW0y7zHP28ly9h5rQzkn\",\n  \"deleted\": true\n}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets delete the files\n",
    "openai.File.delete(\"file-OtfnvW0y7zHP28ly9h5rQzkn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T10:08:23.234704Z",
     "start_time": "2023-10-13T10:08:22.756406Z"
    }
   },
   "id": "6dd42ded7601e6f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f842196e5883543d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
