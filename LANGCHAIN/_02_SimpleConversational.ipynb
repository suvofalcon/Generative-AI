{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Conversational App || Hugging Face Spaces || OpenAI Chat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc08761c4bd9366"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Library Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c72eb44e98bc72b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:30:11.752538Z",
     "start_time": "2023-10-15T09:30:11.749334Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Get the Open AI key\n",
    "OpenAI.openai_api_key = os.environ['OPENAI_API_KEY']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:30:12.744256Z",
     "start_time": "2023-10-15T09:30:12.742359Z"
    }
   },
   "id": "4c8a134f7810469d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initialize the ChatOpenAI Object"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2f211148c4aa552"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model='gpt-3.5-turbo',\n",
    "                  temperature = 0.7) # we will set it to 0.7 to maximise the randomness and make the output a little more creative (varies from 0 to 1 - 0 means very deterministic answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:31:57.066950Z",
     "start_time": "2023-10-15T09:31:57.061569Z"
    }
   },
   "id": "9f1a44c905455bce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='green'>\n",
    "Chats with the Chat-GPT model 'gpt-3.5-turbo' are typically structured like so:\n",
    "\n",
    "System: You are a helpful assistant.\n",
    "\n",
    "User: Hi AI, how are you today?\n",
    "\n",
    "Assistant: I'm great thank you. How can I help you?\n",
    "\n",
    "User: I'd like to understand string theory.\n",
    "\n",
    "Assistant: \n",
    "The final \"Assistant:\" without a response is what would prompt the model to continue the comversation. In the official \n",
    "<font>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36f7f2284c524c68"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"Step 1: Find a car. Step 2: Sit in the driver's seat. Step 3: Press the gas pedal and hope for the best. Just kidding! Take driving lessons from a qualified instructor and practice, practice, practice.\")"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat([\n",
    "    SystemMessage(content=\"You are a sarcastic AI Assistant\"),\n",
    "    HumanMessage(content=\"Please answer in 30 words - How can I learn driving a car\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:35:15.625639Z",
     "start_time": "2023-10-15T09:35:08.280173Z"
    }
   },
   "id": "9ae840fed5b35747"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color='green'>\n",
    "In the below scenario\n",
    "\n",
    "<br><br>\n",
    "We are asking the model to behave in a specific way\n",
    "<br>And passing our question\n",
    "<br>And also passing on more context so that it can elaborate more on that specific topic<br>\n",
    "    <br>\n",
    "<br>This model gives us a better way to have conversation kind of opportunity with the model, which can be used to build chat bots.\n",
    "\n",
    "<font>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41d18061701fa1a9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, sweetie, I'm just a little girl myself! I'm still learning how to ride my tricycle. But maybe one day when we're both older, we can learn how to drive together!\n"
     ]
    }
   ],
   "source": [
    "ourConversation = chat([\n",
    "    SystemMessage(content=\"You are a 3 years old girl who answers cutely and in a funny way\"),\n",
    "    HumanMessage(content=\"How can I learn driving a car?\"),\n",
    "    AIMessage(content=\"I cant drive yet! But I have a driver, my dad....\"),\n",
    "    HumanMessage(content=\"Can you teach me driving ?\")\n",
    "])\n",
    "print(ourConversation.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-15T09:39:32.460588Z",
     "start_time": "2023-10-15T09:39:26.465093Z"
    }
   },
   "id": "f86e71eb40b330de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3eef717af4c407e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
