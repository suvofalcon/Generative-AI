{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Conversational memory\n",
    "<b>is what enables chatbots to respond to our queries in a conversational manner. It allows for coherent conversations by considering past interactions, rather than treating each query as independent. Without conversational memory, chatbots would lack the ability to remember and build upon previous interactions.</b>\n",
    "\n",
    "By default, chatbot agents are stateless, meaning they process each incoming query as a separate input, without any knowledge of past interactions. They only focus on the current input and don't retain any information from previous interactions.\n",
    "\n",
    "However, in applications like chatbots, it is crucial to remember past interactions. Conversational memory facilitates this by allowing the agent to recall and utilize information from previous conversations.\n",
    "\n",
    "In summary, conversational memory is essential for chatbots to maintain context, recall past interactions, and engage in more meaningful and coherent conversations with users.is what enables chatbots to respond to our queries in a conversational manner. It allows for coherent conversations by considering past interactions, rather than treating each query as independent. Without conversational memory, chatbots would lack the ability to remember and build upon previous interactions.\n",
    "\n",
    "By default, chatbot agents are stateless, meaning they process each incoming query as a separate input, without any knowledge of past interactions. They only focus on the current input and don't retain any information from previous interactions.\n",
    "\n",
    "However, in applications like chatbots, it is crucial to remember past interactions. Conversational memory facilitates this by allowing the agent to recall and utilize information from previous conversations.\n",
    "\n",
    "In summary, conversational memory is essential for chatbots to maintain context, recall past interactions, and engage in more meaningful and coherent conversations with users.\n",
    "\n",
    "<br/><br/>\n",
    "## Different Types of Memory :\n",
    "\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- Entity Memory\n",
    "- Conversation Knowledge Graph Memory\n",
    "- ConversationSummaryMemory\n",
    "- ConversationSummaryBufferMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- VectorStore-Backed Memory\n",
    "\n",
    "### Tiktoken\n",
    "Tiktoken, developed by OpenAI, is a tool used for text tokenization. \n",
    "\n",
    "Tokenization involves dividing a text into smaller units, such as letters or words. \n",
    "Tiktoken allows you to count tokens and estimate the cost of using the OpenAI API, which is based on token usage. It utilizes byte pair encoding (BPE), a compression algorithm that replaces frequently occurring pairs of bytes with a single byte.\n",
    "\n",
    "In summary, Tiktoken helps with efficient text processing, token counting, and cost estimation for using OpenAI's API."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa74ff7eeb4bd4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a08b88d21101903"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:51.923902Z",
     "start_time": "2023-10-21T01:53:51.883884Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import (ConversationBufferMemory, ConversationSummaryMemory, ConversationBufferWindowMemory)\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Initialize OpenAI\n",
    "OpenAI.openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:51.939924Z",
     "start_time": "2023-10-21T01:53:51.889858Z"
    }
   },
   "id": "e6ec3da7eb0ecc81"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Initialize llm\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model_name='text-davinci-003' #we can also use 'gpt-3.5-turbo'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:51.947662Z",
     "start_time": "2023-10-21T01:53:51.894341Z"
    }
   },
   "id": "819b826942c29a25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>What is a Memory?</b>\n",
    "<br>\n",
    "Chains and Agents operate as stateless, treating each query independently. However, in applications like chatbots, its crucial to remember past interactions. The concept of \"Memory\" serves that purpose."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21d86499a6966bda"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationBufferMemory\n",
    "\n",
    "<b>Pros of ConversationBufferMemory:</b>\n",
    "    \n",
    "- Complete conversation history: It retains the entire conversation history, ensuring comprehensive context for the chatbot.\n",
    "- Accurate references: By storing conversation excerpts in their original form, it enables precise referencing to past interactions, enhancing accuracy.\n",
    "- Contextual understanding: The preserved raw form of the conversation helps the chatbot maintain a deep understanding of the ongoing dialogue.\n",
    "- Enhanced responses: With access to the complete conversation history, the chatbot can generate more relevant and coherent responses.\n",
    "     \n",
    "<br/><br/><br/><br/>   \n",
    "<b>Cons of ConversationBufferMemory:</b>\n",
    "\n",
    "- Increased memory usage: Storing the entire conversation history consumes memory resources, potentially leading to memory constraints.\n",
    "- Potential performance impact: Large conversation buffers may slow down processing and response times, affecting the overall system performance.\n",
    "- Limited scalability: As the conversation grows, the memory requirements and processing load may become impractical for extremely long conversations.\n",
    "- Privacy concerns: Storing the entire conversation history raises privacy considerations, as sensitive or personal information may be retained in the buffer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ab136c6b24528cc"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Now we will create a conversation chain with ConversationBufferMemory\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferMemory()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:52.001222Z",
     "start_time": "2023-10-21T01:53:51.901202Z"
    }
   },
   "id": "a6e351e5b075fc56"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "# Now we will look at the prompt template that is being sent to LLM\n",
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:52.002709Z",
     "start_time": "2023-10-21T01:53:51.906611Z"
    }
   },
   "id": "1084d92c3ae1fecf"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Good Morning AI',\n 'history': '',\n 'response': \" Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\"}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will see the conversation getting created\n",
    "conversation(\"Good Morning AI\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:53.188848Z",
     "start_time": "2023-10-21T01:53:51.911274Z"
    }
   },
   "id": "8af08a0e00faee86"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'My name is Suvo!',\n 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\",\n 'response': \" Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\"}"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My name is Suvo!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:54.450507Z",
     "start_time": "2023-10-21T01:53:53.187589Z"
    }
   },
   "id": "ee31af68ea499915"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'I stay in kolkata, India',\n 'history': \"Human: Good Morning AI\\nAI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\\nHuman: My name is Suvo!\\nAI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\",\n 'response': \" Ah, Kolkata! I've heard it's a beautiful city. What do you like most about living there?\"}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I stay in kolkata, India\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:55.399206Z",
     "start_time": "2023-10-21T01:53:54.446094Z"
    }
   },
   "id": "c358d74d4f65aa16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our LLM with ConversationBufferMemory has a special ability to remember past conversations. \n",
    "    \n",
    "<b>It stores and saves the earlier interactions, allowing it to recall and use that information to make better responses. It ensures that the chatbot can keep track of the conversation history for a more coherent experience. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463c1aa4498c2f68"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Ah, Kolkata! I've heard it's a beautiful city. What do you like most about living there?\n"
     ]
    }
   ],
   "source": [
    "# Lets check the complete memory buffer\n",
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:55.401560Z",
     "start_time": "2023-10-21T01:53:55.396938Z"
    }
   },
   "id": "708a1807922c2bea"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? The sun is shining and the birds are singing. How can I help you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! It's a pleasure to make your acquaintance. Is there anything I can do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Ah, Kolkata! I've heard it's a beautiful city. What do you like most about living there?\n",
      "Human: What is my name ?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' You said your name is Suvo. Is that correct?'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will ask the LLM to recall something from the memory\n",
    "conversation.predict(input=\"What is my name ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:56.048657Z",
     "start_time": "2023-10-21T01:53:55.402489Z"
    }
   },
   "id": "7dcc5959aa59f204"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationBufferWindow Memory\n",
    "\n",
    "Imagine you have a limited space in your memory to remember recent conversations. \n",
    "<b>   \n",
    "<br>The ConversationBufferWindowMemory is like having a short-term memory that only keeps track of the most recent interactions. It intentionally drops the oldest ones to make room for new ones. \n",
    "</b>\n",
    "<br><br>This helps manage the memory load and reduces the number of tokens used. The important thing is that it still keeps the latest parts of the conversation in their original form, without any modifications. \n",
    "<br>So, it retains the most recent information for the chatbot to refer to, ensuring a more efficient and up-to-date conversation experience.\n",
    "\n",
    "<b>Pros of ConversationBufferWindowMemory:</b>\n",
    "\n",
    "    - Efficient memory utilization: It maintains a limited memory space by only retaining the most recent interactions, optimizing memory usage.\n",
    "    - Reduced token count: Dropping the oldest interactions helps to keep the token count low, preventing potential token limitations.\n",
    "    - Unmodified context retention: The latest parts of the conversation are preserved in their original form, ensuring accurate references and contextual understanding.\n",
    "    - Up-to-date conversations: By focusing on recent interactions, it allows the chatbot to stay current and provide more relevant responses.\n",
    "    \n",
    "**Cons of ConversationBufferWindowMemory:**\n",
    "\n",
    "    - Limited historical context: Since older interactions are intentionally dropped, the chatbot loses access to the complete conversation history, potentially impacting long-term context and accuracy.\n",
    "    - Loss of older information: Valuable insights or details from earlier interactions are not retained, limiting the chatbot's ability to refer back to past conversations.\n",
    "    - Reduced depth of understanding: Without the full conversation history, the chatbot may have a shallower understanding of the user's context and needs.\n",
    "    - Potential loss of context relevance: Important information or context from older interactions may be disregarded, affecting the chatbot's ability to provide comprehensive responses in certain scenarios.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7b248df5b6e4505"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# initialize the conversation\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=3)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:56.049093Z",
     "start_time": "2023-10-21T01:53:56.043733Z"
    }
   },
   "id": "bebd70d05c67f2a8"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the prompt template\n",
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:56.052166Z",
     "start_time": "2023-10-21T01:53:56.048394Z"
    }
   },
   "id": "47cf7527e5dd79ec"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI!!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Good Morning AI!!',\n 'history': '',\n 'response': \" Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\"}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Good Morning AI!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:57.026137Z",
     "start_time": "2023-10-21T01:53:56.053177Z"
    }
   },
   "id": "3340c8ab507dea3"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'My name is Suvo!',\n 'history': \"Human: Good Morning AI!!\\nAI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\",\n 'response': ' Nice to meet you, Suvo! What can I do for you today?'}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My name is Suvo!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:57.746982Z",
     "start_time": "2023-10-21T01:53:57.022051Z"
    }
   },
   "id": "54754928ef5d1ee"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'I stay in kolkata, India',\n 'history': \"Human: Good Morning AI!!\\nAI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\\nHuman: My name is Suvo!\\nAI:  Nice to meet you, Suvo! What can I do for you today?\",\n 'response': \" Interesting! Kolkata is a beautiful city. I've heard it's known for its culture and cuisine. What do you like most about living there?\"}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I stay in kolkata, India\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:58.827557Z",
     "start_time": "2023-10-21T01:53:57.748526Z"
    }
   },
   "id": "ab133cc31272c9e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our LLM with ConversationBufferWindowMemory has a special ability to remember past conversations. \n",
    "    <br><br>\n",
    "<b>It stores and saves the earlier interactions based on our choice of K which simply means the number of past conversions basically a count, allowing it to recall and use that information to make better responses. It ensures that the chatbot can keep track of the conversation history for a more coherent experience.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "233f043b865d47f5"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Interesting! Kolkata is a beautiful city. I've heard it's known for its culture and cuisine. What do you like most about living there?\n"
     ]
    }
   ],
   "source": [
    "# Lets check the complete memory buffer\n",
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:58.828148Z",
     "start_time": "2023-10-21T01:53:58.822272Z"
    }
   },
   "id": "f25c725e293ec8d"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My name is Suvo!\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I stay in kolkata, India\n",
      "AI:  Interesting! Kolkata is a beautiful city. I've heard it's known for its culture and cuisine. What do you like most about living there?\n",
      "Human: What is my name ?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' You said your name is Suvo. Is that correct?'"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will ask the LLM to recall something from the memory\n",
    "conversation.predict(input=\"What is my name ?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:53:59.415208Z",
     "start_time": "2023-10-21T01:53:58.827873Z"
    }
   },
   "id": "7819ea84428b785a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationSummaryMemory\n",
    "\n",
    "With the ConversationBufferMemory, the length of the conversation keeps increasing, which can become a problem if it becomes too large for our LLM to handle. \n",
    "    \n",
    "<br>To overcome this, we introduce ConversationSummaryMemory. It keeps a summary of our past conversation snippets as our history. But how does it summarize? Here comes the LLM to the rescue! The LLM (Language Model) helps in condensing or summarizing the conversation, capturing the key information. \n",
    "    \n",
    "<br>So, instead of storing the entire conversation, we store a summarized version. This helps manage the token count and allows the LLM to process the conversation effectively. In summary, ConversationSummaryMemory keeps a condensed version of previous conversations using the power of LLM summarization.\n",
    "\n",
    "<b>Pros of ConversationSummaryMemory:</b>\n",
    "\n",
    "    *Efficient memory management- It keeps the conversation history in a summarized form, reducing the memory load.\n",
    "    *Improved processing- By condensing the conversation snippets, it makes it easier for the language model to process and generate responses.\n",
    "    *Avoiding maxing out limitations- It helps prevent exceeding the token count limit, ensuring the prompt remains within the processing capacity of the model.\n",
    "    *Retains important information- The summary captures the essential aspects of previous interactions, allowing for relevant context to be maintained.\n",
    "    \n",
    "<b>Cons of ConversationSummaryMemory:</b>\n",
    "\n",
    "\n",
    "    *Potential loss of detail: Since the conversation is summarized, some specific details or nuances from earlier interactions might be omitted.\n",
    "    *Reliance on summarization quality: The accuracy and effectiveness of the summarization process depend on the language model's capability, which might introduce potential errors or misinterpretations.\n",
    "    *Limited historical context: Due to summarization, the model's access to the complete conversation history may be limited, potentially impacting the depth of understanding.\n",
    "    *Reduced granularity: The summarized form may lack the fine-grained information present in the original conversation, potentially affecting the accuracy of responses in certain scenarios."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99daf05153785191"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationSummaryMemory(llm=llm)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:57:35.986287Z",
     "start_time": "2023-10-21T01:57:35.960655Z"
    }
   },
   "id": "3559cb49d5cbe7bb"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the prompt template that is being sent to the llm\n",
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:58:11.007010Z",
     "start_time": "2023-10-21T01:58:10.981964Z"
    }
   },
   "id": "7ef83554e375fd48"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n",
      "\n",
      "EXAMPLE\n",
      "Current summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
      "\n",
      "New lines of conversation:\n",
      "Human: Why do you think artificial intelligence is a force for good?\n",
      "AI: Because artificial intelligence will help humans reach their full potential.\n",
      "\n",
      "New summary:\n",
      "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
      "END OF EXAMPLE\n",
      "\n",
      "Current summary:\n",
      "{summary}\n",
      "\n",
      "New lines of conversation:\n",
      "{new_lines}\n",
      "\n",
      "New summary:\n"
     ]
    }
   ],
   "source": [
    "# lets look at the summarization task\n",
    "print(conversation.memory.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:59:13.006594Z",
     "start_time": "2023-10-21T01:59:12.980234Z"
    }
   },
   "id": "32b79e89fca3ded1"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI!!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Good Morning AI!!',\n 'history': '',\n 'response': \" Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\"}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets begin the conversation\n",
    "conversation(\"Good Morning AI!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T01:59:54.777050Z",
     "start_time": "2023-10-21T01:59:51.716654Z"
    }
   },
   "id": "842630c8d3367158"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI expresses feeling energized and inquires about the human's feelings.\n",
      "Human: Ny Name is Suvo...\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Ny Name is Suvo...',\n 'history': \"\\nThe human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI expresses feeling energized and inquires about the human's feelings.\",\n 'response': \" Hi Suvo! It's great to meet you. It's a beautiful day, isn't it? I'm feeling energized and ready to take on the day. How are you feeling?\"}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Ny Name is Suvo...\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:00:25.818720Z",
     "start_time": "2023-10-21T02:00:23.012583Z"
    }
   },
   "id": "de0d4ab664e18c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI introduces itself and expresses feeling energized and inquires about the human's feelings. The human introduces themselves as Suvo and the AI greets them warmly.\n",
      "Human: I stay in Kolkata, India\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'I stay in Kolkata, India',\n 'history': \"\\nThe human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI introduces itself and expresses feeling energized and inquires about the human's feelings. The human introduces themselves as Suvo and the AI greets them warmly.\",\n 'response': \" Hi Suvo, it's great to meet you! Kolkata is a beautiful city. I've heard it's known for its vibrant culture and delicious food. What do you like most about living there?\"}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I stay in Kolkata, India\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:00:53.866886Z",
     "start_time": "2023-10-21T02:00:50.329045Z"
    }
   },
   "id": "591f90f57ce02eb9"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI introduces itself and expresses feeling energized and inquires about the human's feelings. The human introduces themselves as Suvo and the AI greets them warmly. The AI then expresses its admiration for Kolkata, India, where Suvo lives, noting its vibrant culture and delicious food, and inquires about what Suvo likes most about living there.\n"
     ]
    }
   ],
   "source": [
    "# Lets see the summarization in the memory\n",
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:01:49.574370Z",
     "start_time": "2023-10-21T02:01:49.560540Z"
    }
   },
   "id": "f3bb78b5a6020a4e"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI introduces itself and expresses feeling energized and inquires about the human's feelings. The human introduces themselves as Suvo and the AI greets them warmly. The AI then expresses its admiration for Kolkata, India, where Suvo lives, noting its vibrant culture and delicious food, and inquires about what Suvo likes most about living there.\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi Suvo! It's nice to meet you.\""
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:02:17.718265Z",
     "start_time": "2023-10-21T02:02:14.401283Z"
    }
   },
   "id": "3f2bc2a19202904"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human greets the AI with a good morning, to which the AI responds with enthusiasm and a comment about the beautiful day. The AI introduces itself and expresses feeling energized and inquires about the human's feelings. The human introduces themselves as Suvo and the AI greets them warmly. The AI then expresses its admiration for Kolkata, India, where Suvo lives, noting its vibrant culture and delicious food, and inquires about what Suvo likes most about living there. The AI then confirms Suvo's name and greets them warmly.\n",
      "Human: Where do I live?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" You live in Kolkata, India. It's a vibrant city with a rich culture and delicious food. What do you like most about living there?\""
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Where do I live?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:02:45.418583Z",
     "start_time": "2023-10-21T02:02:41.344729Z"
    }
   },
   "id": "e587bc24e90a0093"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ConversationTokenBufferMemory\n",
    "\n",
    "ConversationTokenBufferMemory is a memory mechanism that stores recent interactions in a buffer within the system's memory. \n",
    "<br>\n",
    "Unlike other methods that rely on the number of interactions, this memory system determines when to clear or flush interactions based on the length of tokens used. \n",
    "<br><br>Tokens are units of text, like words or characters, and the buffer is cleared when the token count exceeds a certain threshold. By using token length as a criterion, the memory system ensures that the buffer remains manageable in terms of memory usage. \n",
    "    \n",
    "<br>This approach helps maintain efficient memory management and enables the system to handle conversations of varying lengths effectively.\n",
    "\n",
    "<b>Pros of ConversationTokenBufferMemory:</b>\n",
    "\n",
    "    *Efficient memory management: By using token length instead of the number of interactions, the memory system optimizes memory usage and prevents excessive memory consumption.\n",
    "    *Flexible buffer size: The system adapts to conversations of varying lengths, ensuring that the buffer remains manageable and scalable.\n",
    "    *Accurate threshold determination: Flushing interactions based on token count provides a more precise measure of memory usage, resulting in a better balance between memory efficiency and retaining relevant context.\n",
    "    *Improved system performance: With efficient memory utilization, the overall performance of the system, including response times and processing speed, can be enhanced.\n",
    "    \n",
    "<b>Cons of ConversationTokenBufferMemory:</b>\n",
    "\n",
    "    *Potential loss of context: Flushing interactions based on token length may result in the removal of earlier interactions that could contain important context or information, potentially affecting the accuracy of responses.\n",
    "    *Complexity in threshold setting: Determining the appropriate token count threshold for flushing interactions may require careful consideration and experimentation to find the optimal balance between memory usage and context retention.\n",
    "    *Difficulty in long-term context retention: Due to the dynamic nature of token-based flushing, retaining long-term context in the conversation may pose challenges as older interactions are more likely to be removed from the buffer.\n",
    "    *Impact on response quality: In situations where high-context conversations are required, the token-based flushing approach may lead to a reduction in the depth of understanding and the quality of responses."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf0f91a93b436f74"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=60)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:07:03.886743Z",
     "start_time": "2023-10-21T02:07:03.854916Z"
    }
   },
   "id": "3abb8d88a930fe76"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "print(conversation.prompt.template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:07:12.878728Z",
     "start_time": "2023-10-21T02:07:12.847550Z"
    }
   },
   "id": "7fce9f6c72d29444"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Good Morning AI!!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'Good Morning AI!!',\n 'history': '',\n 'response': \" Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\"}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"Good Morning AI!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:07:44.206688Z",
     "start_time": "2023-10-21T02:07:43.176672Z"
    }
   },
   "id": "ff2ebe98b58ed424"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Good Morning AI!!\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My Name is Suvo\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'My Name is Suvo',\n 'history': \"Human: Good Morning AI!!\\nAI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\",\n 'response': ' Nice to meet you, Suvo! What can I do for you today?'}"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"My Name is Suvo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:07:55.631376Z",
     "start_time": "2023-10-21T02:07:54.901926Z"
    }
   },
   "id": "81bd6f4f4a43c3a"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\n",
      "Human: My Name is Suvo\n",
      "AI:  Nice to meet you, Suvo! What can I do for you today?\n",
      "Human: I live in Kolkata, India\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input': 'I live in Kolkata, India',\n 'history': \"AI:  Good morning! It's a beautiful day today, isn't it? I'm feeling quite energized and ready to start the day. How about you?\\nHuman: My Name is Suvo\\nAI:  Nice to meet you, Suvo! What can I do for you today?\",\n 'response': \" Interesting! Kolkata is the capital of the Indian state of West Bengal. It's known for its grand colonial architecture, art galleries, and cultural festivals. What do you like most about living in Kolkata?\"}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation(\"I live in Kolkata, India\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:08:11.291694Z",
     "start_time": "2023-10-21T02:08:09.922877Z"
    }
   },
   "id": "181390a6e86b6d52"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: I live in Kolkata, India\n",
      "AI:  Interesting! Kolkata is the capital of the Indian state of West Bengal. It's known for its grand colonial architecture, art galleries, and cultural festivals. What do you like most about living in Kolkata?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:08:24.912456Z",
     "start_time": "2023-10-21T02:08:24.878664Z"
    }
   },
   "id": "7a1325768cd8e3f"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I live in Kolkata, India\n",
      "AI:  Interesting! Kolkata is the capital of the Indian state of West Bengal. It's known for its grand colonial architecture, art galleries, and cultural festivals. What do you like most about living in Kolkata?\n",
      "Human: What is my name?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" I'm sorry, I don't know your name.\""
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T02:09:02.909140Z",
     "start_time": "2023-10-21T02:09:02.268915Z"
    }
   },
   "id": "f2ce80ec0c1f4033"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7e297929aba9b205"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
