{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with all PDF files and OpenAI\n",
    "\n",
    "### Libray Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /usr/local/Caskroom/miniconda/base/envs/genai/lib/python3.11/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# Read the OpenAI key\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a PDF file and Read its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv(\"AI_DATASETS_PATH\")\n",
    "PDF_PATH = os.path.join(DATA_DIR, \"genai_datasets/Docs/yolov7paper.pdf\")\n",
    "\n",
    "# Initialize PDF Reader\n",
    "reader = PdfReader(PDF_PATH)\n",
    "\n",
    "# Read the data (extract the data from PDF) and put it in variable raw_text\n",
    "raw_text = \"\"\n",
    "for index, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Text into Smaller Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the chunks(number of chunks splitted) - 84\n"
     ]
    }
   ],
   "source": [
    "# Now we will split the text we read into smaller chunks so that during information retrieval we dont hit the maximum token limit\n",
    "# OpenAI models such as GPT 3.5 or GPT 4, have a maximum token limit, which restricts the input length.\n",
    "# The token limit for gpt-3.5-turbo is 4096 tokens, whereas the token limits for gpt-4-8k and gpt-4-32k are 8192 and 32768 respectively.\n",
    "\n",
    "textsplitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    # chunk size of 1000 Token each and there is going to be an overlap of 200 tokens between the consecutive chunks\n",
    "    # first chunk 1000 charaters long, Next chunk will include last 200 charaters from the first chunk\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 200,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "# Now we will convert text into chunks\n",
    "texts = textsplitter.split_text(raw_text)\n",
    "\n",
    "print(f\"Length of the chunks(number of chunks splitted) - {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1: Comparison with other real-time object detectors, our\n",
      "proposed methods achieve state-of-the-arts performance.\n",
      "opment of MCUNet [49, 48] and NanoDet [54] focused on\n",
      "producing low-power single-chip and improving the infer-\n",
      "ence speed on edge CPU. As for methods such as YOLOX\n",
      "[21] and YOLOR [81], they focus on improving the infer-\n",
      "ence speed of various GPUs. More recently, the develop-\n",
      "ment of real-time object detector has focused on the de-\n",
      "sign of efﬁcient architecture. As for real-time object de-\n",
      "tectors that can be used on CPU [54, 88, 84, 83], their de-\n",
      "sign is mostly based on MobileNet [28, 66, 27], ShufﬂeNet\n",
      "[92, 55], or GhostNet [25]. Another mainstream real-time\n",
      "object detectors are developed for GPU [81, 21, 97], they\n",
      "mostly use ResNet [26], DarkNet [63], or DLA [87], and\n",
      "then use the CSPNet [80] strategy to optimize the architec-\n",
      "ture. The development direction of the proposed methods in\n",
      "this paper are different from that of the current mainstream\n"
     ]
    }
   ],
   "source": [
    "# check once chunk\n",
    "print(texts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI embeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# We want to compute the embedding on our document, there is a bunch of vector stores that langchain support we will use FAISS\n",
    "# FAISS will take the text chunks, find the corresponding embedding and that will be stored in the Document Search\n",
    "docsearch = FAISS.from_texts(texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Query - Answer using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(api_key=openai_key), chain_type='stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The authors of this article are Chien-Yao Wang, Alexey Bochkovskiy, and Hong-Yuan Mark Liao.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who are the authors of this article YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "\n",
    "# Pass the docsearch to OpenAI and have LLM answer back\n",
    "chain.run(input_documents=docs, question=query, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' YOLOv7 surpasses YOLOv4, YOLOR-CSP, YOLOv4-tiny-31.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"YOLOv7 surpasses which models\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' YOLOv7 is trained on MS COCO dataset from scratch without using any other datasets or pre-trained weights.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What dataset YOLOv7 is trained on?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" No, I don't know about Google Bard.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Do you know about Google Bard?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
